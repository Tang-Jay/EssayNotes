# ç›¸å…³å·¥ä½œå†™ä½œ {#related-work}
`whatï¼Œwhyï¼Œwhenï¼Œhow`

## æ€ç»´å¯¼å›¾
![](images/RelatedWork.png)

## å‡†å¤‡å·¥ä½œ
Related Work means that the overall goal is to describe the related research areas and to place your method's contributions to the field in this context.

### é˜…è¯»æ–‡çŒ®
- ç ”ç©¶æ–¹å‘çš„ç°çŠ¶å’ŒèƒŒæ™¯
- è®ºæ–‡æ‰€è§£å†³çš„ç—›ç‚¹
- è®ºæ–‡æå‡ºçš„æ–¹æ³•:ä¸»è¦æµç¨‹ï¼Œæ ¸å¿ƒç®—æ³•ï¼Œåˆ›æ–°ç‚¹
- è®ºæ–‡çš„å®éªŒç»“æœå’Œç»“è®º:æ–¹æ³•çš„ä¼˜è¶Šæ€§å’Œå±€é™æ€§

### è®°å½•æ–‡çŒ®
- é¢˜ç›®
- èƒŒæ™¯ã€ç°çŠ¶ã€ç—›ç‚¹
- æ–¹æ³•ã€é‡è¦ç»†èŠ‚ã€åˆ›æ–°ç‚¹
- å®éªŒç»“æœã€ç»“è®º

ğŸ’¡å°†ç¬”è®°è®°åœ¨åŒä¸€ä¸ªæ–‡æ¡£é‡Œ

**ä¾‹å­ 1**

|||
|:---------| :-------------|
| é¢˜ç›® | Deep Residual Learning for Image Recognition  | 
| ç°çŠ¶ | The depth of representations is of central importance for many visual recognition tasks. |
| ç—›ç‚¹ | Deeper neural networks are more difficult to train because of the vanishing/exploding gradient. While several solutions can deal with this issue, the accuracy of existing approaches still degrades rapidly with the networks depth increasing. |
| æ–¹æ³• | Introducing a deep residual learning framework.  |
| åˆ›æ–°ç‚¹ | The shortcut connections simply perform identity mapping.  |
| å®éªŒç»“æœåŠç»“è®º |The results show that their approach allows deep network to be easier to train due to less complex strcuture and obtained the state-of-the-art performance on multiple image classification datasets|

ğŸ’¡åœ¨æ’°å†™ç›¸å…³å·¥ä½œç« èŠ‚å‰ï¼Œåœ¨é˜…è¯»ç ”ç©¶ç›¸å…³çš„æ–‡çŒ®æ—¶ï¼Œä»æ‰€ç”¨æŠ€æœ¯ï¼Œç ”ç©¶æ–¹å‘ç­‰è§’åº¦å°½é‡è¾¾åˆ°é¢é¢ä¿±åˆ°çš„é˜…è¯»å’Œç†è§£ã€‚åŒæ—¶ï¼Œåœ¨é˜…è¯»æ—¶ä¸€å®šè¦åšå¥½ç¬”è®°ï¼Œå¹¶æ ¹æ®æ–‡çŒ®ç±»å‹è¿›è¡Œåˆ†ç±»ã€‚è¿™æ ·å¯ä»¥ä½¿åœ¨æ’°å†™ç›¸å…³å·¥ä½œç« èŠ‚æ—¶ï¼Œé«˜æ•ˆï¼Œå‡†ç¡®ï¼Œå¿«é€Ÿã€‚

## æ’°å†™ç›¸å…³å·¥ä½œ
### ç›®çš„
- The overall goal is to describe the **related research areas** and to place your method's contributions to the field in this context.

- By clearly describing previous work, you can **better describe the current
limitations** and **the need for new methodology**.

- It also gives you an opportunity to demonstrate knowledge of the area and **helps others relate your current work to other scientific areas**.

### åŸºæœ¬ç»“æ„

- æ€»èµ·/æ¦‚æ‹¬æœ¬èŠ‚å†…å®¹
- æ€»ç»“å„æ–‡çŒ®
  - æ®µè½åˆ†ç±»
  - æ¯ç¯‡æ–‡çŒ®æ€»ç»“ç»“æ„
  


**ç¬¬ä¸€éƒ¨åˆ†:æ€»ç»“ç°æœ‰ç›¸å…³æ–¹æ³•/ç« èŠ‚çš„æƒ…å†µï¼ˆå¯çœç•¥ï¼‰**

**æ–¹æ³•1:**

- 1-2å¥æ€»èµ·
  - In the past decade, many related studies have been proposed and published.
  - Since 1980, XXX (ç ”ç©¶é¢†åŸŸ) has been rapidly developed.
  
- æ€»ç»“ç°æœ‰ç›¸å…³å·¥ä½œçš„æƒ…å†µï¼Œå¯¹å·²æœ‰æ–¹æ³•è¿›è¡Œåˆ†ç±»æˆ–æ—¶åºæ’åˆ—
  - åˆ†ç±»  
  These approaches can be mainly categorized into three classes:1.XXX;2.XXX;3.XXX.
  - æ—¶åº  
  Early studies mainly focused on XXX (æ—©æœŸæ–¹æ³•æ¦‚è¿°), which XXX (æ—©æœŸæ–¹æ³•çš„ç¼ºé™·). During XXX (ä¸­æœŸæŸæ®µæ—¶é—´), most researchers XXX (ä¸­æœŸæ–¹æ³•æ¦‚è¿°), but XXX (ä¸­æœŸæ–¹æ³•ç¼ºé™·). In recent years, with the XXX (è¿‘æœŸæ–°æ–¹æ³•çš„æ¥æº) becoming XXX (è¿‘æœŸæ–¹æ³•æ¦‚è¿°), this type of techniques have been widely employed in XXX (æœ¬æ–‡ç ”ç©¶é¢†åŸŸ).

**æ–¹æ³•2:**

- å¯¹æœ¬ç« èŠ‚ç»“æ„è¿›è¡Œæ¦‚è¿°
  - This section presents XXX in XXX. Then, XXX and XXX  are introduced in XXX , which  are followed by XXX.


**ç¬¬äºŒéƒ¨åˆ†:åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†/æ®µè½è¯¦ç»†æ€»ç»“å„ç¯‡è®ºæ–‡**

**è§„åˆ’æ®µè½**

1. æŒ‰æŠ€æœ¯è·¯çº¿åˆ†ç±»:æ¯ç§æŠ€æœ¯è·¯çº¿çš„è®ºæ–‡æ”¾åœ¨åˆ†/æ®µè½è¿›è¡Œæ€»ç»“
1. æŒ‰åº”ç”¨é¢†åŸŸåˆ†ç±»:æ¯ç§åº”ç”¨é¢†åŸŸçš„è®ºæ–‡æ”¾åœ¨ä¸€ä¸ªéƒ¨åˆ†/æ®µè½è¿›è¡Œæ€»ç»“
1. æŒ‰æŠ€æœ¯-åº”ç”¨åˆ†ç±»:ä¸æœ¬æ–‡æŠ€æœ¯ç›¸å…³çš„è®ºæ–‡æ”¾åœ¨ä¸€ä¸ªéƒ¨åˆ†/æ®µè½ ï¼Œä¸åº”ç”¨é¢†åŸŸç›¸å…³çš„è®ºæ–‡æ”¾åœ¨ä¸€ä¸ªéƒ¨åˆ†/æ®µè½
1. æŒ‰æŠ€æœ¯å‘å±•é˜¶æ®µåˆ†ç±»:æ¯ä¸ªé˜¶æ®µæ”¾åœ¨ä¸€ä¸ªéƒ¨åˆ†/æ®µè½
1. æ ¹æ®å…¶ä»–ç ”ç©¶é€»è¾‘æ¥åˆ†ç±»

**ä¸€äº›ä¾‹å­**

- æŒ‰æŠ€æœ¯åˆ†ç±»   
  Albanie, Samuel, et al. "Emotion recognition in speech using cross-modal transfer in the wild." Proceedings of the 26th ACM international conference on Multimedia. 2018.
  - Video as stack of still images
  - Video as spatial-temporal volumes
  - Short and Long-Term Dynamics
  - Multi-Stream Networks
  - Motion Information
  - Learning to Rank Videos

- æŒ‰é¢†åŸŸåˆ†ç±»  
Hu, Han, et al. "Relation networks for object detection." Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition. 2018.
  - Object relation in post processing
  - Sequential relation modeling
  - Human centered scenarios
  - Duplicate removal

- æŒ‰ç ”ç©¶é€»è¾‘å’ŒæŠ€æœ¯è·¯çº¿åˆ†ç±»   
Junior, J. C. S.J., et al. "First impressions: A survey on computer vision-based apparent personality trait analysis." IEEE Transactions on Affective Computing
  - The importance of first impressions in our lives
  - How challenging and subjective can be apparent personality trait
labeling/evaluation?
  - Still Images
  - Image sequence
  - Audiovisual trait prediction
  - Multimodal trait prediction

**æ–‡çŒ®æ€»ç»“æ ¼å¼**

`ç›®çš„-->æ–¹æ³•-->ç»†èŠ‚/åˆ›æ–°ç‚¹-->ç»“æœ/ç»“è®º`

- Author proposed a method that XXX (æ–¹æ³•ç»†èŠ‚/æ–¹æ³•æµç¨‹), which XXX (ç»“æœ/ç»“è®º).

- To deal with XXX (ç—›ç‚¹), XXX (æ–¹æ³•) was employed by sb, which XXX (è§£å†³ç—›ç‚¹çš„ç»†èŠ‚), and achieved XXX (ç»“æœ/ç»“è®º).

**ä¸€äº›ä¸¾ä¾‹**

- å¯¹æ¯ä¸€ç¯‡æ–‡çŒ®è¯¦ç»†åˆ†æ

Biel et al. [17] studied personality impressions in conversational videos (vlogs) from facial expression analysis (ç›®çš„). 
In their work, a subset of the Youtube vlog dataset [57] is adopted, as well as a facial expression model based on Facial Action Coding System (FACS) (æ–¹æ³•).
The task of first impressions prediction is addressed using Support Vector Regression (SVR) combined with statistics of facial activity based on frame-by-frame estimates (ç»†èŠ‚1).
Moreover, they analyzed what specific facial expressions are most prominent for modeling each of the different impressions (ç»†èŠ‚2) .
Results show that extraversion is the trait showing the largest activity cue utilization, which is related to the evidence found in the literature that extraversion is typically easier to judge [58], [59] (ç»“æœ).
Later, Aran and Gatica-Perez [60] studied the use of social media content as a domain to learn apparent personality traits, in particular extraversion, aiming to transfer the knowledge extracted from conversational videos to small group settings (ç›®çš„).
Ridge Regression and SVM classifiers are combined with statistics extracted from weighted Motion Energy Images for the task of personality impressions prediction (æ–¹æ³•/ç»†èŠ‚).

- å¯¹æ–‡çŒ®è¿›è¡Œæ–¹æ³•åˆ†ç±»

In low-level vision and computer graphics, for solving Partial Differential Equations (PDEs)(ç›®çš„), 
the widely used Multigrid method [3] reformulates the system as subproblems at multiple scales,
where each subproblem is responsible for the residual solution between a coarser and a finer scale(æ–¹æ³•/ç»†èŠ‚).
 An alternative to Multigrid is hierarchical basis pre-conditioning [44, 45], which relies
on variables that represent residual vectors between two scales(æ–¹æ³•/ç»†èŠ‚). It has been shown [3, 44, 45] that these solvers converge much faster than standard solvers that are unaware of the residual nature of the solutions (ç»“æœç»“è®º). These methods suggest that a good reformulation or
preconditioning can simplify the optimization.

- å¯¹æ–‡çŒ®è¿›è¡Œæ—¶åºåˆ†ç±»

Practices and theories that lead to shortcut connections [2, 33, 48] have been studied for a long time(ç›®çš„).
 An early practice of training multi-laver perceptrons (MLPs) (æ–¹æ³•åç§°) is to add a
linear layer connected from the network input to thy, output [33, 48] (æ–¹æ³•ç»†èŠ‚). In [43, 24], a few
intermediate layers are directly connected to auxiliary classifiers for addressing vanishing/exploding
gradients. (æ–¹æ³•ç»†èŠ‚) The papers of [38, 37, 31, 46] propose methods for centering layer reponses,
gradients, and propagated errors, implemented by shortcut connections. In [43], an inception" layer
is com-posed of a shortcut branch and a few deeper branches. (æ–¹æ³•ç»†èŠ‚)

**ç¬¬ä¸‰éƒ¨åˆ†:æ€»ç»“å·²æœ‰æ–¹æ³•çš„ç—›ç‚¹ï¼ˆä¸æœ¬æ–‡ç ”ç©¶æ–¹å‘ç›¸å…³ï¼‰**

- å†æ¬¡æ€»ç»“å·²æœ‰æ–¹æ³•çš„ç¼ºé™·å’Œç—›ç‚¹
- æ€»ç»“æœ¬æ–‡æ‰€ä¾èµ–æŠ€æœ¯çš„ä¼˜åŠ¿
- å†æ¬¡å¼ºè°ƒæœ¬æ–‡ç ”ç©¶åŠ¨æœº


## å®æˆ˜æ¼”ç»ƒ

**é€šè¿‡ç¬”è®°å¿«é€Ÿå¼•å‡ºæ–‡çŒ®**

**1. å›é¡¾ç¬”è®°**

|||
|:---------| :-------------|
| é¢˜ç›® | Deep Residual Learning for Image Recognition  | 
| ç°çŠ¶ | The depth of representations is of central importance for many visual recognition tasks. |
| ç—›ç‚¹ | Deeper neural networks are more difficult to train because of the vanishing/exploding gradient. While several solutions can deal with this issue, the accuracy of existing approaches still degrades rapidly with the networks depth increasing. |
| æ–¹æ³• | Introducing a deep residual learning framework.  |
| åˆ›æ–°ç‚¹ | The shortcut connections simply perform identity mapping.  |
| å®éªŒç»“æœåŠç»“è®º |The results show that their approach allows deep network to be easier to train due to less complex strcuture and obtained the state-of-the-art performance on multiple image classification datasets|

**2. æç‚¼ç¬”è®°**

|||
|:---------| :-------------|
|ç›®çš„|To deal with the exploding gradient problem during the training as well as enhancing the performance of deep models.|
|æ–¹æ³•|He et al. [1] proposed a deep residual network.|
|ç»†èŠ‚|The shortcut connections simply perfrom identity mapping, and their outputs are added to the outputs of the stacked layers.|
|ç»“æœ|Obtained the state-of-the-art performance on multiple datasets and competitions.|

**3. æ•´ç†æˆæ®µ**

To deal with the exploding gradient problem during the training as well as enhancing the performance of deep models. He et al. [1] proposed a deep residual network, where the shortcut connections perform identity mapping, and their outputs are added to the
outputs of the stacked layers. The results showed that this model obtained the state-of-the-art performance on multiple datasets and competitions.






